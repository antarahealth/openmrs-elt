{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import time\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext,SparkSession\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_submit_str = ('--driver-memory 30g --executor-memory 1g --packages org.apache.spark:spark-sql_2.11:2.3.0 '\n",
    "'--jars /home/jovyan/jars/spark-cassandra-connector.jar'\n",
    "' --conf spark.shuffle.partitions=50,spark.executor.extraJavaOptions=\"-XX:+UseG1GC -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintAdaptiveSizePolicy -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -Xms88g -Xmx88g -XX:InitiatingHeapOccupancyPercent=35 -XX:ConcGCThread=20\" pyspark-shell')\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = spark_submit_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get flat obs from cassandra\n",
    "def get_flat_obs(spark): \n",
    "    return spark.read\\\n",
    "    .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=\"flat_obs_rebuild\", keyspace=\"etl\")\\\n",
    "    .option(\"partitionColumn\", \"patient_id\")\\\n",
    "    .option(\"fetchsize\", 10000)\\\n",
    "    .option(\"lowerBound\", 1)\\\n",
    "    .option(\"upperBound\", 8000000)\\\n",
    "    .option(\"numPartitions\", 800)\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs_schema():\n",
    "    schema = ArrayType(\n",
    "            StructType([\n",
    "                StructField('obs_id'     , IntegerType()   , True),\n",
    "                StructField('concept_id',  IntegerType()   , True),\n",
    "                StructField('obs_group_id',IntegerType()   , True),\n",
    "                StructField('parent_concept_id', IntegerType()   , True),\n",
    "                StructField('value',  StringType()   , True),\n",
    "                StructField('value_type',StringType()   , True),\n",
    "                StructField('obs_datetime' ,TimestampType()    , True)\n",
    "            ])\n",
    "        )\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orders_schema():\n",
    "    schema = ArrayType(\n",
    "            StructType([\n",
    "                StructField('order_id',  IntegerType()   , True),\n",
    "                StructField('order_concept_id',  IntegerType()   , True),\n",
    "                StructField('date_activated',  TimestampType()   , True),\n",
    "                StructField('voided',  IntegerType()   , True)\n",
    "            ]))\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_cassandra(hiv_summary_df):\n",
    "             hiv_summary_df.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "            .options(table=\"hiv_summary\", keyspace=\"etl\")\\\n",
    "            .mode(\"append\")\\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "sc = SparkContext(master=\"local[*]\",appName=\"flatHivSummary\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started app\n",
      "+----------+------------+------------+-------------------+-----------+------+---------+----------+---------------------+--------------------+-----------+-------------------+----------------------+---------------------+------------------+\n",
      "|patient_id|patient_uuid|encounter_id| encounter_datetime|location_id|gender|birthdate|death_date|is_clinical_encounter|       analysis_date|out_of_care|    enrollment_date|enrollment_location_id|arv_start_location_id|viral_load_ordered|\n",
      "+----------+------------+------------+-------------------+-----------+------+---------+----------+---------------------+--------------------+-----------+-------------------+----------------------+---------------------+------------------+\n",
      "|     13460|        null|     6932376|2017-06-07 10:48:43|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131079|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131081|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131080|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131082|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131088|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131084|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131085|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131087|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7131089|2017-09-14 08:45:08|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "|     13460|        null|     7581252|2018-04-09 10:56:30|         13|     M|     null|      null|                    1|2018-06-27 13:22:...|       null|2017-06-07 10:48:43|                    13|                   13|                 1|\n",
      "+----------+------------+------------+-------------------+-----------+------+---------+----------+---------------------+--------------------+-----------+-------------------+----------------------+---------------------+------------------+\n",
      "\n",
      "Finished: Wed Jun 27 13:34:49 2018\n",
      "Took 746.355708 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.utcnow()\n",
    "print(\"started app\")\n",
    "\n",
    "#extract flat_obs from cassandra\n",
    "obs_order_df = get_flat_obs(spark)\n",
    "\n",
    "#convert stringified obs to parsed obs\n",
    "obs_parsed = obs_order_df.withColumn(\"parsed_obs\", f.from_json(\"obs\", get_obs_schema()))\n",
    "\n",
    "#convert stringified orders to parsed obs\n",
    "orders_parsed = obs_parsed.withColumn(\"parsed_orders\", f.from_json(\"orders\", get_orders_schema()))\n",
    "\n",
    "#explode nested obs structure\n",
    "exploded_obs = orders_parsed.withColumn(\"flattened_obs\", f.explode(\"parsed_obs\"))\n",
    "\n",
    "exploded_obs.withColumn(\"flattened_orders\", f.explode(\"parsed_orders\")).createOrReplaceTempView(\"obs\")\n",
    "\n",
    "# transformations\n",
    "spark.sql(\"\"\"select\n",
    "            *,\n",
    "            case \n",
    "                when flattened_obs.concept_id = 9082 and flattened_obs.value = '9036' then 'negative'\n",
    "                else null end as patient_care_status,\n",
    "            case \n",
    "                when flattened_obs.concept_id = 5303 and flattened_obs.value= '822' then 'exposed'\n",
    "                when flattened_obs.concept_id = 5303 and flattened_obs.value = '664' then 'negative'\n",
    "                when flattened_obs.concept_id = 5303 and flattened_obs.value = '1067' then 'unknown'\n",
    "                else null end as child_hiv_status,\n",
    "            case\n",
    "              when encounter_type in (1,2,3,4,10,14,15,17,19,26,32,\n",
    "              33,34,47,105,106,112,113,114,117,120,127,128,129,138,153,154,158) then 1\n",
    "            else null end as is_clinical_encounter\n",
    "            from obs\n",
    "        \"\"\").createOrReplaceTempView(\"hiv_summary_stage_0\")\n",
    "\n",
    "spark.sql(\"\"\"select \n",
    "             *,\n",
    "             case \n",
    "                 when flattened_obs.concept_id = 7013 and flattened_obs.value is not null then to_date(flattened_obs.value)\n",
    "                 when flattened_obs.concept_id = 7015 and flattened_obs.value is not null then to_date(flattened_obs.value)\n",
    "                 when encounter_type not in (21,99999) then encounter_datetime\n",
    "                 else null end as enrollment_date,\n",
    "             case \n",
    "                 when flattened_obs.concept_id = 1946 and flattened_obs.value = \"1065\" then 1\n",
    "                 when flattened_obs.concept_id = 1285 and flattened_obs.value in (\"1287\",\"9068\") then 1\n",
    "                 when flattened_obs.concept_id = 1596 then 1\n",
    "                 when flattened_obs.concept_id = 9082 and flattened_obs.value in (\"159\",\"9036\",\"9083\",\"1287\",\"9068\",\"9079\", \"9504\", \"1285\") then 1\n",
    "                 when encounter_type = 31 then 1\n",
    "                 else null end as out_of_care,\n",
    "             case \n",
    "                 when flattened_orders.order_concept_id = 856 then 1\n",
    "                 else null end as viral_load_ordered,\n",
    "             case \n",
    "                 when flattened_obs.concept_id = 1255 and flattened_obs.value is not null then location_id\n",
    "                 when flattened_obs.concept_id IN (1250, 1088, 2154) then location_id\n",
    "                 else null end as arv_location_id\n",
    "             from hiv_summary_stage_0\n",
    "             where \n",
    "                 child_hiv_status is null \n",
    "                 and patient_care_status is null \n",
    "                 and is_clinical_encounter = 1 \n",
    "             \"\"\").createOrReplaceTempView(\"hiv_summary_stage_1\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"select patient_id,\n",
    "                    encounter_id,\n",
    "                    first(location_id) as location_id,\n",
    "                    first(encounter_datetime) as encounter_datetime,\n",
    "                    first(encounter_type) as encounter_type,\n",
    "                    first(enrollment_date, true) as enrollment_date,\n",
    "                    first(out_of_care, true) as out_of_care,\n",
    "                    first(location_id) as enrollment_location_id,\n",
    "                    first(viral_load_ordered, true) as viral_load_ordered,\n",
    "                    first(arv_location_id, true) as arv_location_id,\n",
    "                    first(gender) as gender,\n",
    "                    first(birthdate) as birthdate,\n",
    "                    first(death_date) as death_date,\n",
    "                    first(is_clinical_encounter) as is_clinical_encounter\n",
    "                    from hiv_summary_stage_1\n",
    "                    group by patient_id, encounter_id\n",
    "        \"\"\").createOrReplaceTempView(\"hiv_summary_stage_2\")\n",
    "\n",
    "hiv_summary_3 = spark.sql(\"\"\"select patient_id,\n",
    "                    null as patient_uuid,\n",
    "                    encounter_id,\n",
    "                    encounter_datetime,\n",
    "                    location_id,\n",
    "                    gender,\n",
    "                    birthdate,\n",
    "                    death_date,\n",
    "                    is_clinical_encounter,\n",
    "                    current_timestamp() as analysis_date,\n",
    "                    first(out_of_care, true) over p as out_of_care,\n",
    "                    first(enrollment_date, true) over p as enrollment_date,\n",
    "                    case when enrollment_date is not null then location_id\n",
    "                    else null end as enrollment_location_id,\n",
    "                    first(arv_location_id, true) over p as arv_start_location_id,\n",
    "                    viral_load_ordered\n",
    "                    from hiv_summary_stage_2\n",
    "                    window p as (partition by patient_id order by encounter_datetime)\n",
    "        \"\"\")\n",
    "\n",
    "hiv_summary_3.createOrReplaceTempView(\"hiv_summary_stage_3\")\n",
    "\n",
    "hiv_summary = spark.sql(\"\"\"select patient_id,\n",
    "                    null as patient_uuid,\n",
    "                    encounter_id,\n",
    "                    encounter_datetime,\n",
    "                    location_id,\n",
    "                    gender,\n",
    "                    birthdate,\n",
    "                    death_date,\n",
    "                    is_clinical_encounter,\n",
    "                    analysis_date,\n",
    "                    out_of_care,\n",
    "                    enrollment_date,\n",
    "                    first(enrollment_location_id, true) over p as enrollment_location_id,\n",
    "                    arv_start_location_id,\n",
    "                    viral_load_ordered\n",
    "                    from hiv_summary_stage_3\n",
    "                    window p as (partition by patient_id order by encounter_datetime)\n",
    "        \"\"\")\n",
    "\n",
    "hiv_summary.createOrReplaceTempView(\"hiv_sum\")\n",
    "\n",
    "\n",
    "#hiv_summary = spark.sql(\"select *,  from hiv_sum\")\n",
    "#spark.sql(\"select * from hiv_sum where ordered_viral_load is not null\").show(50)\n",
    "spark.sql(\"select * from hiv_sum where patient_id = 13460\").show(50)\n",
    "\n",
    "#print(hiv_summary.count())\n",
    "load_to_cassandra(hiv_summary)\n",
    "\n",
    "end_time = datetime.datetime.utcnow()\n",
    "print(\"Finished: \" + time.ctime()) \n",
    "print(\"Took {0} seconds\".format((end_time - start_time).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
